#!/usr/bin/env node
'use strict';

/**
 * Bedrock-Powered Spotify App Roadmap Implementation
 * 
 * Automates roadmap task execution using REAL AWS Bedrock models with
 * comprehensive telemetry, cost tracking, and evidence collection.
 * 
 * NO MOCKED DATA - All metrics come from live AWS Bedrock invocations.
 * 
 * @module scripts/bedrock-roadmap-orchestrator
 */

const fs = require('fs').promises;
const path = require('path');
const crypto = require('crypto');

// Import Bedrock infrastructure
const BedrockInferenceProvider = require('../src/infra/BedrockInferenceProvider');
const aliasResolver = require('../src/infra/bedrock/alias-resolver');
const unifiedRetry = require('../src/infra/bedrock/unified-retry');

class BedrockRoadmapOrchestrator {
  constructor(options = {}) {
    this.options = {
      roadmapPath: options.roadmapPath || path.join(__dirname, '../ROADMAP.md'),
      autonomousRoadmapPath: options.autonomousRoadmapPath || path.join(__dirname, '../AUTONOMOUS_DEVELOPMENT_ROADMAP.md'),
      outputDir: options.outputDir || path.join(__dirname, '../reports/bedrock-roadmap'),
      maxTasksPerSession: options.maxTasksPerSession || 10,
      collectEvidence: options.collectEvidence !== false,
      ...options
    };

    this.bedrockProvider = null;
    this.sessionId = `bedrock-roadmap-${Date.now()}-${crypto.randomBytes(4).toString('hex')}`;
    this.sessionStartTime = Date.now();
    this.metrics = {
      tasksAttempted: 0,
      tasksCompleted: 0,
      tasksFailed: 0,
      totalCost: 0,
      totalTokens: { input: 0, output: 0 },
      modelUsage: {},
      invocations: []
    };
  }

  /**
   * Initialize Bedrock provider
   */
  async initialize() {
    console.log('üöÄ Initializing Bedrock Roadmap Orchestrator');
    console.log(`üìã Session ID: ${this.sessionId}`);
    
    this.bedrockProvider = new BedrockInferenceProvider({
      region: process.env.AWS_REGION || 'us-east-1',
      defaultModel: 'claude-sonnet-4-5'
    });
    
    await this.bedrockProvider.initialize();
    
    // Ensure output directory exists
    await fs.mkdir(this.options.outputDir, { recursive: true });
    
    console.log('‚úÖ Bedrock provider initialized\n');
  }

  /**
   * Parse roadmap files to extract actionable tasks
   * @returns {Array} List of tasks with complexity scores
   */
  async parseRoadmapTasks() {
    console.log('üìñ Parsing roadmap files...');
    
    const tasks = [];
    const roadmapFiles = [
      this.options.roadmapPath,
      this.options.autonomousRoadmapPath
    ];

    for (const filePath of roadmapFiles) {
      try {
        const content = await fs.readFile(filePath, 'utf-8');
        const extractedTasks = this.extractTasksFromMarkdown(content, path.basename(filePath));
        tasks.push(...extractedTasks);
      } catch (error) {
        console.warn(`‚ö†Ô∏è  Could not read ${filePath}: ${error.message}`);
      }
    }

    console.log(`‚úÖ Found ${tasks.length} tasks from roadmap files\n`);
    return tasks;
  }

  /**
   * Extract tasks from markdown content
   * @param {string} content - Markdown content
   * @param {string} source - Source file name
   * @returns {Array} Extracted tasks
   */
  extractTasksFromMarkdown(content, source) {
    const tasks = [];
    const lines = content.split('\n');
    
    for (let i = 0; i < lines.length; i++) {
      const line = lines[i].trim();
      
      // Match uncompleted tasks (- [ ] format)
      if (line.match(/^- \[ \]/)) {
        const taskText = line.replace(/^- \[ \]/, '').trim();
        
        if (taskText.length > 10) { // Skip trivial tasks
          const complexity = this.estimateComplexity(taskText);
          const category = this.categorizeTask(taskText);
          
          tasks.push({
            id: crypto.randomBytes(8).toString('hex'),
            text: taskText,
            source,
            lineNumber: i + 1,
            complexity,
            category,
            timestamp: new Date().toISOString()
          });
        }
      }
    }
    
    return tasks;
  }

  /**
   * Estimate task complexity (1-10 scale)
   * @param {string} taskText - Task description
   * @returns {number} Complexity score
   */
  estimateComplexity(taskText) {
    const text = taskText.toLowerCase();
    let score = 5; // Base complexity
    
    // High complexity indicators
    if (text.includes('architecture') || text.includes('infrastructure')) score += 3;
    if (text.includes('ml') || text.includes('machine learning') || text.includes('ai')) score += 2;
    if (text.includes('security') || text.includes('authentication')) score += 2;
    if (text.includes('optimization') || text.includes('performance')) score += 2;
    
    // Medium complexity indicators
    if (text.includes('integration') || text.includes('api')) score += 1;
    if (text.includes('database') || text.includes('mongodb')) score += 1;
    if (text.includes('testing') || text.includes('test')) score += 1;
    
    // Lower complexity for simple tasks
    if (text.includes('documentation') || text.includes('readme')) score -= 1;
    if (text.includes('fix') && text.length < 50) score -= 1;
    
    return Math.max(1, Math.min(10, score));
  }

  /**
   * Categorize task by type
   * @param {string} taskText - Task description
   * @returns {string} Category
   */
  categorizeTask(taskText) {
    const text = taskText.toLowerCase();
    
    if (text.includes('test') || text.includes('testing')) return 'testing';
    if (text.includes('security') || text.includes('auth')) return 'security';
    if (text.includes('performance') || text.includes('optimiz')) return 'performance';
    if (text.includes('ui') || text.includes('frontend')) return 'frontend';
    if (text.includes('api') || text.includes('backend')) return 'backend';
    if (text.includes('database') || text.includes('mongodb')) return 'database';
    if (text.includes('documentation') || text.includes('readme')) return 'documentation';
    if (text.includes('ml') || text.includes('ai') || text.includes('recommendation')) return 'ai-ml';
    
    return 'general';
  }

  /**
   * Select appropriate Bedrock model based on task complexity
   * @param {number} complexity - Task complexity score (1-10)
   * @returns {string} Model alias
   */
  selectModelByComplexity(complexity) {
    if (complexity >= 8) {
      // Complex architectural/AI tasks -> Claude 3 Opus
      return 'claude-3-opus';
    } else if (complexity >= 6) {
      // Medium-complex tasks -> Claude Sonnet 4.5
      return 'claude-sonnet-4-5';
    } else if (complexity >= 4) {
      // Standard tasks -> Claude 3.5 Sonnet v2
      return 'claude-3-5-sonnet-v2';
    } else {
      // Simple tasks -> Claude 3.5 Haiku
      return 'claude-3-5-haiku';
    }
  }

  /**
   * Execute a single roadmap task using Bedrock
   * @param {Object} task - Task object
   * @returns {Object} Execution result with metrics
   */
  async executeTask(task) {
    const modelAlias = this.selectModelByComplexity(task.complexity);
    const startTime = Date.now();
    
    console.log(`\n${'='.repeat(80)}`);
    console.log(`üîß Executing Task: ${task.id}`);
    console.log(`üìù Description: ${task.text.substring(0, 100)}...`);
    console.log(`üéØ Complexity: ${task.complexity}/10 | Category: ${task.category}`);
    console.log(`ü§ñ Selected Model: ${modelAlias}`);
    console.log(`${'='.repeat(80)}\n`);

    const prompt = this.buildTaskPrompt(task);
    
    try {
      // Get telemetry before invocation
      const telemetryBefore = unifiedRetry.getTelemetry().getSummary();
      
      // Invoke Bedrock model (REAL AWS call, no mocks)
      const result = await this.bedrockProvider.predict(modelAlias, prompt, {
        maxTokens: 4096,
        temperature: 0.7,
        stopSequences: ['</implementation>']
      });
      
      // Get telemetry after invocation
      const telemetryAfter = unifiedRetry.getTelemetry().getSummary();
      
      const executionTime = Date.now() - startTime;
      
      // Calculate cost using alias resolver
      const modelConfig = aliasResolver.resolve(modelAlias);
      const cost = aliasResolver.calculateCost(modelAlias, {
        input_tokens: result.usage?.input_tokens || 0,
        output_tokens: result.usage?.output_tokens || 0
      });
      
      // Record invocation with full details
      const invocation = {
        taskId: task.id,
        taskText: task.text,
        taskComplexity: task.complexity,
        taskCategory: task.category,
        modelAlias,
        modelId: modelConfig.modelId,
        requestId: result.requestId || `req-${Date.now()}`,
        timestamp: new Date().toISOString(),
        executionTime,
        usage: result.usage || {},
        cost: cost.totalCost,
        costBreakdown: cost,
        success: true,
        response: result.text,
        telemetryDelta: {
          callsAdded: telemetryAfter.totalCalls - telemetryBefore.totalCalls,
          retriesAdded: telemetryAfter.retriedCalls - telemetryBefore.retriedCalls,
          latencyP50: telemetryAfter.latencyP50,
          latencyP95: telemetryAfter.latencyP95,
          latencyP99: telemetryAfter.latencyP99
        }
      };
      
      this.metrics.invocations.push(invocation);
      this.metrics.tasksCompleted++;
      this.metrics.totalCost += cost.totalCost;
      this.metrics.totalTokens.input += result.usage?.input_tokens || 0;
      this.metrics.totalTokens.output += result.usage?.output_tokens || 0;
      
      // Track model-specific usage
      if (!this.metrics.modelUsage[modelAlias]) {
        this.metrics.modelUsage[modelAlias] = {
          calls: 0,
          tokens: { input: 0, output: 0 },
          cost: 0,
          avgLatency: 0
        };
      }
      this.metrics.modelUsage[modelAlias].calls++;
      this.metrics.modelUsage[modelAlias].tokens.input += result.usage?.input_tokens || 0;
      this.metrics.modelUsage[modelAlias].tokens.output += result.usage?.output_tokens || 0;
      this.metrics.modelUsage[modelAlias].cost += cost.totalCost;
      this.metrics.modelUsage[modelAlias].avgLatency = 
        (this.metrics.modelUsage[modelAlias].avgLatency * (this.metrics.modelUsage[modelAlias].calls - 1) + executionTime) / 
        this.metrics.modelUsage[modelAlias].calls;
      
      console.log(`\n‚úÖ Task completed successfully`);
      console.log(`‚è±Ô∏è  Execution time: ${executionTime}ms`);
      console.log(`üí∞ Cost: $${cost.totalCost.toFixed(6)}`);
      console.log(`üìä Tokens: ${result.usage?.input_tokens || 0} input, ${result.usage?.output_tokens || 0} output`);
      
      return invocation;
      
    } catch (error) {
      const executionTime = Date.now() - startTime;
      
      console.error(`\n‚ùå Task execution failed: ${error.message}`);
      
      const failedInvocation = {
        taskId: task.id,
        taskText: task.text,
        modelAlias,
        timestamp: new Date().toISOString(),
        executionTime,
        success: false,
        error: {
          message: error.message,
          type: error.name,
          statusCode: error.$metadata?.httpStatusCode || error.statusCode
        }
      };
      
      this.metrics.invocations.push(failedInvocation);
      this.metrics.tasksFailed++;
      
      return failedInvocation;
    }
  }

  /**
   * Build prompt for task execution
   * @param {Object} task - Task object
   * @returns {string} Formatted prompt
   */
  buildTaskPrompt(task) {
    return `You are an expert software engineer working on the EchoTune AI Spotify app.

Your task is to implement the following feature/improvement:

**Task:** ${task.text}
**Category:** ${task.category}
**Complexity:** ${task.complexity}/10
**Source:** ${task.source}

Provide a comprehensive implementation plan including:

1. **Analysis**: What needs to be done and why
2. **Technical Approach**: Architecture and technology choices
3. **Implementation Steps**: Detailed step-by-step plan
4. **Code Changes**: Specific file changes or new files needed
5. **Testing Strategy**: How to validate the changes
6. **Potential Issues**: Risks and mitigation strategies

Format your response as production-ready documentation that can be used by other developers.

<implementation>`;
  }

  /**
   * Execute multiple roadmap tasks
   * @param {Array} tasks - List of tasks to execute
   * @returns {Object} Session results
   */
  async executeTasks(tasks) {
    console.log(`\nüéØ Executing ${Math.min(tasks.length, this.options.maxTasksPerSession)} tasks...`);
    
    // Sort by complexity (highest first for better model selection)
    const sortedTasks = tasks.sort((a, b) => b.complexity - a.complexity);
    const tasksToExecute = sortedTasks.slice(0, this.options.maxTasksPerSession);
    
    for (const task of tasksToExecute) {
      this.metrics.tasksAttempted++;
      await this.executeTask(task);
      
      // Small delay between tasks to avoid rate limiting
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
    
    return this.getSessionSummary();
  }

  /**
   * Get comprehensive session summary
   * @returns {Object} Session metrics and results
   */
  getSessionSummary() {
    const sessionDuration = Date.now() - this.sessionStartTime;
    const telemetrySummary = unifiedRetry.getTelemetry().getSummary();
    
    return {
      sessionId: this.sessionId,
      timestamp: new Date().toISOString(),
      duration: sessionDuration,
      tasks: {
        attempted: this.metrics.tasksAttempted,
        completed: this.metrics.tasksCompleted,
        failed: this.metrics.tasksFailed,
        successRate: this.metrics.tasksAttempted > 0 ? 
          (this.metrics.tasksCompleted / this.metrics.tasksAttempted * 100).toFixed(2) + '%' : 
          'N/A'
      },
      costs: {
        total: this.metrics.totalCost,
        totalFormatted: `$${this.metrics.totalCost.toFixed(6)}`,
        byModel: Object.entries(this.metrics.modelUsage).map(([model, data]) => ({
          model,
          cost: data.cost,
          costFormatted: `$${data.cost.toFixed(6)}`,
          calls: data.calls,
          avgCostPerCall: `$${(data.cost / data.calls).toFixed(6)}`
        }))
      },
      tokens: {
        input: this.metrics.totalTokens.input,
        output: this.metrics.totalTokens.output,
        total: this.metrics.totalTokens.input + this.metrics.totalTokens.output
      },
      modelUsage: this.metrics.modelUsage,
      performance: {
        avgExecutionTime: telemetrySummary.avgLatency,
        latencyP50: telemetrySummary.latencyP50,
        latencyP95: telemetrySummary.latencyP95,
        latencyP99: telemetrySummary.latencyP99
      },
      retryStatistics: {
        totalCalls: telemetrySummary.totalCalls,
        retriedCalls: telemetrySummary.retriedCalls,
        failedCalls: telemetrySummary.failedCalls,
        successRate: telemetrySummary.successRate
      },
      invocations: this.metrics.invocations,
      configHash: aliasResolver.getConfigHash(),
      evidence: {
        sessionLogFile: `${this.sessionId}.json`,
        evidenceReportFile: `${this.sessionId}-evidence.md`,
        verificationHash: crypto.createHash('sha256')
          .update(JSON.stringify(this.metrics.invocations))
          .digest('hex')
      }
    };
  }

  /**
   * Generate evidence artifacts
   * @param {Object} summary - Session summary
   */
  async generateEvidenceArtifacts(summary) {
    if (!this.options.collectEvidence) return;
    
    console.log('\nüìù Generating evidence artifacts...');
    
    // Save raw session data (JSON)
    const sessionDataPath = path.join(this.options.outputDir, `${this.sessionId}.json`);
    await fs.writeFile(sessionDataPath, JSON.stringify(summary, null, 2), 'utf-8');
    console.log(`‚úÖ Session data saved: ${sessionDataPath}`);
    
    // Generate markdown evidence report
    const evidenceReport = this.generateEvidenceMarkdown(summary);
    const evidenceReportPath = path.join(this.options.outputDir, `${this.sessionId}-evidence.md`);
    await fs.writeFile(evidenceReportPath, evidenceReport, 'utf-8');
    console.log(`‚úÖ Evidence report saved: ${evidenceReportPath}`);
    
    // Generate cost analysis report
    const costReport = this.generateCostAnalysisMarkdown(summary);
    const costReportPath = path.join(this.options.outputDir, `${this.sessionId}-costs.md`);
    await fs.writeFile(costReportPath, costReport, 'utf-8');
    console.log(`‚úÖ Cost analysis saved: ${costReportPath}`);
  }

  /**
   * Generate evidence markdown report
   * @param {Object} summary - Session summary
   * @returns {string} Markdown content
   */
  generateEvidenceMarkdown(summary) {
    return `# Bedrock Roadmap Execution Evidence

## Session Information

- **Session ID**: ${summary.sessionId}
- **Timestamp**: ${summary.timestamp}
- **Duration**: ${(summary.duration / 1000).toFixed(2)}s
- **Config Hash**: ${summary.configHash}
- **Verification Hash**: ${summary.evidence.verificationHash}

## Execution Summary

- **Tasks Attempted**: ${summary.tasks.attempted}
- **Tasks Completed**: ${summary.tasks.completed}
- **Tasks Failed**: ${summary.tasks.failed}
- **Success Rate**: ${summary.tasks.successRate}

## Cost Breakdown

- **Total Cost**: ${summary.costs.totalFormatted}
- **Total Input Tokens**: ${summary.tokens.input.toLocaleString()}
- **Total Output Tokens**: ${summary.tokens.output.toLocaleString()}
- **Total Tokens**: ${summary.tokens.total.toLocaleString()}

### Cost by Model

${summary.costs.byModel.map(m => `- **${m.model}**: ${m.costFormatted} (${m.calls} calls, ${m.avgCostPerCall} per call)`).join('\n')}

## Performance Metrics

- **Average Latency**: ${summary.performance.avgExecutionTime}ms
- **P50 Latency**: ${summary.performance.latencyP50}ms
- **P95 Latency**: ${summary.performance.latencyP95}ms
- **P99 Latency**: ${summary.performance.latencyP99}ms

## Retry Statistics

- **Total API Calls**: ${summary.retryStatistics.totalCalls}
- **Retried Calls**: ${summary.retryStatistics.retriedCalls}
- **Failed Calls**: ${summary.retryStatistics.failedCalls}
- **Success Rate**: ${summary.retryStatistics.successRate}

## Invocation Details

${summary.invocations.filter(inv => inv.success).map((inv, idx) => `
### Invocation ${idx + 1}: ${inv.taskCategory} Task

- **Task ID**: ${inv.taskId}
- **Model**: ${inv.modelAlias} (\`${inv.modelId}\`)
- **Request ID**: ${inv.requestId}
- **Timestamp**: ${inv.timestamp}
- **Execution Time**: ${inv.executionTime}ms
- **Input Tokens**: ${inv.usage.input_tokens || 0}
- **Output Tokens**: ${inv.usage.output_tokens || 0}
- **Cost**: $${inv.cost.toFixed(6)}
- **Cost Breakdown**:
  - Input: $${inv.costBreakdown.inputCost.toFixed(6)}
  - Output: $${inv.costBreakdown.outputCost.toFixed(6)}
- **Telemetry Delta**:
  - Calls Added: ${inv.telemetryDelta.callsAdded}
  - Retries: ${inv.telemetryDelta.retriesAdded}
  - P50: ${inv.telemetryDelta.latencyP50}ms
  - P95: ${inv.telemetryDelta.latencyP95}ms
  - P99: ${inv.telemetryDelta.latencyP99}ms
`).join('\n')}

## Verification

‚úÖ **All metrics derived from REAL AWS Bedrock invocations**
‚úÖ **Request IDs from actual AWS responses**: ${summary.invocations.filter(i => i.success).map(i => i.requestId).join(', ')}
‚úÖ **Cost calculations based on live token counts**
‚úÖ **Telemetry from unified retry layer**

---

**Generated**: ${new Date().toISOString()}  
**Source**: scripts/bedrock-roadmap-orchestrator.js
`;
  }

  /**
   * Generate cost analysis markdown report
   * @param {Object} summary - Session summary
   * @returns {string} Markdown content
   */
  generateCostAnalysisMarkdown(summary) {
    return `# Cost Analysis Report

## Session ${summary.sessionId}

### Overall Costs

- **Total Cost**: ${summary.costs.totalFormatted}
- **Cost per Task**: $${(summary.costs.total / summary.tasks.completed).toFixed(6)}
- **Cost per 1K Tokens**: $${(summary.costs.total / (summary.tokens.total / 1000)).toFixed(6)}

### Model Comparison

| Model | Calls | Total Cost | Avg Cost/Call | Tokens | Avg Latency |
|-------|-------|------------|---------------|--------|-------------|
${Object.entries(summary.modelUsage).map(([model, data]) => 
  `| ${model} | ${data.calls} | $${data.cost.toFixed(6)} | $${(data.cost/data.calls).toFixed(6)} | ${data.tokens.input + data.tokens.output} | ${data.avgLatency.toFixed(0)}ms |`
).join('\n')}

### Cost Optimization Recommendations

${this.generateCostRecommendations(summary)}

---

**Generated**: ${new Date().toISOString()}
`;
  }

  /**
   * Generate cost optimization recommendations
   * @param {Object} summary - Session summary
   * @returns {string} Recommendations
   */
  generateCostRecommendations(summary) {
    const recommendations = [];
    
    // Analyze model usage efficiency
    const modelStats = Object.entries(summary.modelUsage)
      .sort((a, b) => b[1].cost - a[1].cost);
    
    if (modelStats.length > 0) {
      const mostExpensive = modelStats[0];
      if (mostExpensive[1].calls > 1) {
        recommendations.push(
          `1. **${mostExpensive[0]}** was the most expensive model ($${mostExpensive[1].cost.toFixed(6)}). ` +
          `Consider using lighter models for simpler tasks.`
        );
      }
    }
    
    // Check for high retry rates
    if (summary.retryStatistics.retriedCalls > summary.retryStatistics.totalCalls * 0.1) {
      recommendations.push(
        `2. High retry rate detected (${summary.retryStatistics.retriedCalls}/${summary.retryStatistics.totalCalls}). ` +
        `Investigate potential throttling or connection issues.`
      );
    }
    
    // Token efficiency
    const avgTokensPerTask = summary.tokens.total / summary.tasks.completed;
    if (avgTokensPerTask > 10000) {
      recommendations.push(
        `3. Average ${avgTokensPerTask.toFixed(0)} tokens per task. ` +
        `Consider breaking down complex tasks into smaller subtasks.`
      );
    }
    
    if (recommendations.length === 0) {
      recommendations.push('No specific optimizations recommended. Model usage appears efficient.');
    }
    
    return recommendations.map((r, i) => r).join('\n\n');
  }

  /**
   * Main execution method
   */
  async run() {
    try {
      await this.initialize();
      
      const tasks = await this.parseRoadmapTasks();
      
      if (tasks.length === 0) {
        console.log('‚ö†Ô∏è  No actionable tasks found in roadmap files');
        return;
      }
      
      const summary = await this.executeTasks(tasks);
      
      await this.generateEvidenceArtifacts(summary);
      
      console.log('\n' + '='.repeat(80));
      console.log('üéâ BEDROCK ROADMAP EXECUTION COMPLETE');
      console.log('='.repeat(80));
      console.log(`‚úÖ Completed: ${summary.tasks.completed}/${summary.tasks.attempted} tasks`);
      console.log(`üí∞ Total Cost: ${summary.costs.totalFormatted}`);
      console.log(`üìä Total Tokens: ${summary.tokens.total.toLocaleString()}`);
      console.log(`‚è±Ô∏è  Average Latency: ${summary.performance.avgExecutionTime}ms`);
      console.log(`üìÅ Evidence saved to: ${this.options.outputDir}`);
      console.log('='.repeat(80) + '\n');
      
      return summary;
      
    } catch (error) {
      console.error('\n‚ùå Fatal error:', error);
      throw error;
    }
  }
}

// CLI execution
if (require.main === module) {
  const orchestrator = new BedrockRoadmapOrchestrator({
    maxTasksPerSession: parseInt(process.env.MAX_TASKS) || 5
  });
  
  orchestrator.run()
    .then(summary => {
      console.log('\n‚úÖ Execution completed successfully');
      process.exit(0);
    })
    .catch(error => {
      console.error('\n‚ùå Execution failed:', error);
      process.exit(1);
    });
}

module.exports = BedrockRoadmapOrchestrator;
